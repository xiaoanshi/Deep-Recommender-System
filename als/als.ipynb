{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"../data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(998)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    xs, ys = valid_ratings.nonzero()\n",
    "    indices = list(zip(xs, ys))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    cut = int(p_test * len(indices))\n",
    "    train = valid_ratings.copy()\n",
    "    xs, ys = zip(*indices)\n",
    "    train[xs[:cut], ys[:cut]] = 0\n",
    "    test = valid_ratings.copy()\n",
    "    test[xs[cut:], ys[cut:]] = 0\n",
    "    \n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(ratings, num_items_per_user, num_users_per_item, min_num_ratings=0, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    num_item, num_user = train.shape\n",
    "    item_features = np.random.random((num_features, num_item)) * np.sqrt(5 / num_features) # W\n",
    "    user_features = np.random.random((num_features, num_user)) * np.sqrt(5 / num_features) # Z\n",
    "    #item_features = np.ones((num_features, num_item)) * np.sqrt(3.9/5) * np.sqrt(5 / num_features) # W\n",
    "    #item_features[1,:] = \n",
    "    #user_features = np.ones((num_features, num_user)) * np.sqrt(3.9/5) * np.sqrt(5 / num_features) # Z\n",
    "    #user_features[1,:] = \n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(data, user_features, item_features):\n",
    "    nz_row, nz_col = data.nonzero()\n",
    "    nz = list(zip(nz_row, nz_col))\n",
    "    WZ = item_features.T @ user_features\n",
    "    print(WZ.min(), WZ.max())\n",
    "    s = 0\n",
    "    for u, i in nz:\n",
    "        s += np.square(data[u, i] - WZ[u, i])\n",
    "    return np.sqrt(s / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from random import sample\n",
    "\n",
    "def update_user_feature(ratings, user_features, item_features, lambda_user):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    num_item = ratings.shape[0]\n",
    "    num_user = ratings.shape[1]\n",
    "    num_features = item_features.shape[0]\n",
    "    \n",
    "    batch_size = 3000\n",
    "    batch_user = sample(range(num_user), batch_size)\n",
    "    \n",
    "    for i in tqdm(range(num_user), desc=\"update user\"):\n",
    "        nz = ratings[:, i].nonzero()[0]\n",
    "        y = ratings[nz, i].todense()\n",
    "        X = item_features[:, nz].T\n",
    "        \n",
    "        user_features.T[i] = np.squeeze(np.linalg.inv(X.T.dot(X) + lambda_user * np.eye(X.shape[1])).dot(X.T.dot(y)))\n",
    "    return user_features\n",
    "\n",
    "def update_item_feature(ratings, user_features, item_features, lambda_item):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    xs, ys = ratings.nonzero()\n",
    "    \n",
    "    num_item = ratings.shape[0]\n",
    "    num_user = ratings.shape[1]\n",
    "    num_features = user_features.shape[0]\n",
    "    \n",
    "    batch_size = 300\n",
    "    batch_item = sample(range(num_item), batch_size)\n",
    "    \n",
    "    ratingsT = ratings.T\n",
    "    \n",
    "    for i in tqdm(range(num_item), desc=\"update item\"):\n",
    "        nz = ratingsT[:, i].nonzero()[0]\n",
    "        y = ratingsT[nz, i].todense()\n",
    "        X = user_features[:, nz].T\n",
    "        \n",
    "        item_features[:,i] = np.squeeze(np.linalg.inv(X.T.dot(X) + lambda_item * np.eye(X.shape[1])).dot(X.T.dot(y)))\n",
    "    return item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "from helpers import predict\n",
    "\n",
    "\n",
    "def ALS(train, test, num_features, lambda_user, lambda_item):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    #num_features = 11   # K in the lecture notes\n",
    "    #lambda_user = 1.8\n",
    "    #lambda_item = 1.4 \n",
    "    max_iter = 2\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    tr_error = rmse(train, user_features, item_features)\n",
    "    te_error = rmse(test, user_features, item_features)\n",
    "    print(\"initial train rmse : \", tr_error, \"\\ninitial test rmse : \", te_error)\n",
    "    \n",
    "    train_error_list = [tr_error]\n",
    "    test_error_list = [te_error]\n",
    "\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i >= max_iter:\n",
    "            break\n",
    "            \n",
    "        item_features = update_item_feature(train, user_features, item_features, lambda_item)\n",
    "        user_features = update_user_feature(train, user_features, item_features, lambda_user)\n",
    "        \n",
    "        tr_error = rmse(train, user_features, item_features)\n",
    "        te_error = rmse(test, user_features, item_features)\n",
    "        train_error_list.append(tr_error)\n",
    "        test_error_list.append(te_error)\n",
    "        print(\"train rmse : \", tr_error, \"\\ntest rmse : \", te_error)\n",
    "        i += 1\n",
    "        \n",
    "    plt.plot(train_error_list)\n",
    "    plt.plot(test_error_list)\n",
    "    plt.show()  \n",
    "    WZ = item_features.T @ user_features\n",
    "    return WZ    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = load_data(\"../data/sampleSubmission.csv\")\n",
    "nz = pred.nonzero()\n",
    "WZ = ALS(train, test, 2, 1, 3)\n",
    "WZ[WZ < 1] = 1\n",
    "WZ[WZ > 5] = 5\n",
    "pred[nz] = WZ[nz]\n",
    "predict(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
