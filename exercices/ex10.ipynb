{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"../data/data_train.csv\"\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(998)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    xs, ys = valid_ratings.nonzero()\n",
    "    indices = list(zip(xs, ys))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    cut = int(p_test * len(indices))\n",
    "    train = valid_ratings.copy()\n",
    "    xs, ys = zip(*indices)\n",
    "    train[xs[:cut], ys[:cut]] = 0\n",
    "    test = valid_ratings.copy()\n",
    "    test[xs[cut:], ys[cut:]] = 0\n",
    "    \n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=0, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    avg = test.copy()\n",
    "    avg[avg.nonzero()] = train.sum() / train.size \n",
    "    return np.sqrt(calculate_mse(test, avg).sum() / avg.size)\n",
    "\n",
    "#tr_rmse = baseline_global_mean(train, train)\n",
    "te_rmse = baseline_global_mean(train, test)\n",
    "#print(\"train RMSE : \", tr_rmse)\n",
    "print(\"test RMSE : \", te_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"    \n",
    "    avg = test.copy()\n",
    "    xs, ys = avg.nonzero()\n",
    "    for i in np.arange(train.shape[0]):\n",
    "        avg[i, ys[xs == i]] = train[i, :].sum() / train[i, :].size\n",
    "    return np.sqrt(calculate_mse(avg, test).sum() / avg.size)\n",
    "\n",
    "\n",
    "#tr_rmse = baseline_user_mean(train, train)\n",
    "te_rmse = baseline_user_mean(train, test)\n",
    "#print(\"train RMSE : \", tr_rmse)\n",
    "print(\"test RMSE : \", te_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    avg = test.copy()\n",
    "    xs, ys = avg.nonzero()\n",
    "    for u in np.arange(train.shape[1]):\n",
    "        avg[xs[ys == u], u] = train[:, u].sum() / train[:, u].size    \n",
    "    return np.sqrt(calculate_mse(avg, test).sum()  / avg.size)\n",
    "    \n",
    "\n",
    "#tr_rmse = baseline_item_mean(train, train)\n",
    "te_rmse = baseline_item_mean(train, test)\n",
    "#print(\"train RMSE : \", tr_rmse)\n",
    "print(\"test RMSE : \", te_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import predict\n",
    "\n",
    "def predict_baseline(train, pred):\n",
    "    avg = pred.copy()\n",
    "    xs, ys = avg.nonzero()\n",
    "    for u in np.arange(train.shape[1]):\n",
    "        avg[xs[ys == u], u] = train[:, u].sum() / train[:, u].size\n",
    "    predict(avg)\n",
    "    \n",
    "pred = load_data(\"../data/sampleSubmission.csv\")\n",
    "predict_baseline(train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import predict\n",
    "pred = load_data(\"../data/sampleSubmission.csv\")\n",
    "nz = pred.nonzero()\n",
    "pred[nz] = 4\n",
    "predict(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    num_item, num_user = train.shape\n",
    "    #item_features = np.random.random((num_features, num_item)) * np.sqrt(5 / num_features) # W\n",
    "    #user_features = np.random.random((num_features, num_user)) * np.sqrt(5 / num_features) # Z\n",
    "    item_features = np.ones((num_features, num_item)) * np.sqrt(3.9/5) * np.sqrt(5 / num_features) # W\n",
    "    user_features = np.ones((num_features, num_user)) * np.sqrt(3.9/5) * np.sqrt(5 / num_features) # Z\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_features, item_features = init_MF(train, 20)\n",
    "print(rmse(train, user_features, item_features),rmse(test, user_features, item_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    WZ = (item_features.T @ user_features)\n",
    "    s = 0\n",
    "    for u, i in nz:\n",
    "        s += np.square(data[u, i] - WZ[u, i])\n",
    "    return s / len(nz)\n",
    "    #return np.sum(calculate_mse(data, item_features.T @ user_features) / 2) / nz\n",
    "    #return np.sum(np.square(data - item_features.T @ user_features) / 2) / data.size\n",
    "    #return np.sum(np.square((data - WZ).data) / 2) / data.size\n",
    "    \n",
    "def compute_error2(data, user_features, item_features, lambda_w, lambda_z):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    WZ = data.copy()\n",
    "    nz = WZ.nonzero()\n",
    "    WZ[nz] = (item_features.T @ user_features)[nz]\n",
    "    return (np.sum(calculate_mse(data, WZ)) / data.size) + (lambda_w / 2) * np.linalg.norm(item_features) + (lambda_z / 2) * np.linalg.norm(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_features, item_features = init_MF(train, 20)\n",
    "nz_row, nz_col = test.nonzero()\n",
    "nz_test = list(zip(nz_row, nz_col))\n",
    "compute_error(test, user_features, item_features, nz_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "    \n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        i = 0\n",
    "        for d, n in nz_train:\n",
    "            e = train[d, n] - user_features[:, n].T @ item_features[:, d]\n",
    "            \n",
    "            dw = e * user_features[:, n]\n",
    "            dz = e * item_features[:, d]\n",
    "            item_features[:, d] += gamma * (dw - lambda_item * e) \n",
    "            user_features[:, n] += gamma * (dz - lambda_user * e)\n",
    "            print(dw, dz)\n",
    "            if i > 3:\n",
    "                break\n",
    "            i += 1\n",
    "            \n",
    "            #item_features[:, d] += gamma * (dw - lambda_item * np.linalg.norm(item_features) * 0.001) \n",
    "            #user_features[:, n] += gamma * (dz - lambda_user * np.linalg.norm(user_features) * 0.001)\n",
    "            \n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "    \n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    plt.plot(errors)\n",
    "    plt.show()\n",
    "    \n",
    "matrix_factorization_SGD(train, test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(item_features.shape)\n",
    "print(user_features.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(data, user_features, item_features):\n",
    "    nz_row, nz_col = data.nonzero()\n",
    "    nz = list(zip(nz_row, nz_col))\n",
    "    WZ = item_features.T @ user_features\n",
    "    print(WZ.min(), WZ.max())\n",
    "    s = 0\n",
    "    for u, i in nz:\n",
    "        s += np.square(data[u, i] - WZ[u, i])\n",
    "    return np.sqrt(s / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from random import sample\n",
    "def update_user_feature(ratings, user_features, item_features, lambda_user):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    num_item = ratings.shape[0]\n",
    "    num_user = ratings.shape[1]\n",
    "    num_features = item_features.shape[0]\n",
    "    \n",
    "    XtX = item_features @ item_features.T\n",
    "    \n",
    "    batch_size = 1000\n",
    "    batch_user = sample(range(num_user), batch_size)\n",
    "    \n",
    "    for i in tqdm(range(num_user), desc=\"update user\"):\n",
    "        Xty = item_features @ ratings[:,i]\n",
    "        \n",
    "        for j in range(num_features):\n",
    "            XtX[j, j] += lambda_user * num_item\n",
    "        \n",
    "        user_features.T[i] = np.reshape(np.linalg.solve(XtX, Xty), (num_features))\n",
    "    return user_features\n",
    "\n",
    "def update_item_feature(ratings, user_features, item_features, lambda_item):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    xs, ys = ratings.nonzero()\n",
    "    \n",
    "    num_item = ratings.shape[0]\n",
    "    num_user = ratings.shape[1]\n",
    "    num_features = user_features.shape[0]\n",
    "    \n",
    "    XtX = user_features @ user_features.T\n",
    "    \n",
    "    batch_size = 100\n",
    "    batch_item = sample(range(num_item), batch_size)\n",
    "    \n",
    "    for i in tqdm(range(num_item), desc=\"update item\"):\n",
    "        Xty = user_features @ ratings[i].T\n",
    "        \n",
    "        for j in range(num_features):\n",
    "            XtX[j, j] += lambda_item * num_user\n",
    "            \n",
    "        print(Xty)\n",
    "        item_features.T[i] = np.reshape(np.linalg.solve(XtX, Xty), (num_features))\n",
    "    return item_features\n",
    "\n",
    "\n",
    "def update_user_feature2(ratings, user_features, item_features, lambda_user):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    num_item = ratings.shape[0]\n",
    "    num_user = ratings.shape[1]\n",
    "    num_features = item_features.shape[0]\n",
    "    \n",
    "    batch_size = 2000\n",
    "    batch_user = sample(range(num_user), batch_size)\n",
    "    \n",
    "    for i in tqdm(batch_user, desc=\"update user\"):\n",
    "        nz = ratings[:, i].nonzero()[0]\n",
    "        y = ratings[nz, i].todense()\n",
    "        X = item_features[:, nz].T\n",
    "        \n",
    "        user_features.T[i] = np.squeeze(np.linalg.inv(X.T.dot(X) + lambda_user * np.eye(X.shape[1])).dot(X.T.dot(y)))\n",
    "    return user_features\n",
    "\n",
    "def update_item_feature2(ratings, user_features, item_features, lambda_item):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    xs, ys = ratings.nonzero()\n",
    "    \n",
    "    num_item = ratings.shape[0]\n",
    "    num_user = ratings.shape[1]\n",
    "    num_features = user_features.shape[0]\n",
    "    \n",
    "    batch_size = 40\n",
    "    batch_item = sample(range(num_item), batch_size)\n",
    "    \n",
    "    for i in tqdm(batch_item, desc=\"update item\"):\n",
    "        nz = ratings.T[:, i].nonzero()[0]\n",
    "        y = ratings.T[nz, i].todense()\n",
    "        X = user_features[:, nz].T\n",
    "        \n",
    "        item_features[:,i] = np.squeeze(np.linalg.inv(X.T.dot(X) + lambda_item * np.eye(X.shape[1])).dot(X.T.dot(y)))\n",
    "    return item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from helpers import build_index_groups\n",
    "from helpers import predict\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 5   # K in the lecture notes\n",
    "    lambda_user = 1.5\n",
    "    lambda_item = 1.5\n",
    "    stop_criterion = 1e-2\n",
    "    change = 1\n",
    "    error_list = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    error = rmse(train, user_features, item_features)\n",
    "    print(error)\n",
    "\n",
    "    while True:\n",
    "        item_features = update_item_feature2(train, user_features, item_features, lambda_item)\n",
    "        user_features = update_user_feature2(train, user_features, item_features, lambda_user)\n",
    "        \n",
    "        error = rmse(train, user_features, item_features)\n",
    "        error_list.append(error)\n",
    "        print(error)\n",
    "        if abs(error_list[-2] - error_list[-1]) < stop_criterion:\n",
    "            break\n",
    "        \n",
    "    plt.plot(error_list)\n",
    "    plt.show()\n",
    "    pred = load_data(\"../data/sampleSubmission.csv\")\n",
    "    nz = pred.nonzero()\n",
    "    WZ = item_features.T @ user_features\n",
    "    WZ[WZ < 1] = 1\n",
    "    WZ[WZ > 5] = 5\n",
    "    print(WZ.min(), WZ.max())\n",
    "    print(WZ[nz])\n",
    "    pred[nz] = WZ[nz]\n",
    "    predict(pred)\n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    w = item_features\n",
    "    return np.linalg.inv(w @ w.T + np.identity(w.shape[0]) * lambda_user) @ (w @ train) \n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    z = user_features\n",
    "    return np.linalg.inv(z @ z.T + np.identity(z.shape[0]) * lambda_item) @ (z @ train.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "02ba6606c4404d8e99bb28eaf8a6cb3d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "039d3109501e45b899c4485910d213a2": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0ab7348edbe3478fad08623d27d0af20": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0ae3aef945e444bb913a1de8dc8016f6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0b2d3b20c9624555be31debd27f99c6d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0ba65da5d84f4373925723ce2024dfea": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0ecf287dc5ba471782f73cb3037b1cfa": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "0f6d58e6e9e94d2a92ccd250b36da31b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "10a3aedcd3c442c5b7794f729c6fb75b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "140c993a30394e17accfdafa9561a0e3": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "189866dfeefe4fd68a52eb87d1434bd5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "1a7381f7624a494cbe5563889048016e": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "1d482ee1951c4b49b2410fe03ceb4e17": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "1dcf70f1455a400f9b7b03221d0dd82a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "22f31f28638d496a932afe4b113378c5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "2a24cac7c79c4c0c96aeca689d17c50c": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "2bcda1122682489bb60a86fb3336a796": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "2ea33766491a453088ded95b8ae7fe48": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "322cfe7eabaf486285dc0a931b48b99f": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "33ab4f5b16ed4881b22baeb964a70e49": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "3776f9148ae7462da86f610bbf70e2e5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "3d06641b43f3481ca5414e2fb7c81a30": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "3db67b8b72a643daa69a74d927952789": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "43ab4d0826dc4f4dbd9f87d89448553c": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "440f890cad6841febe0cf0f91f097c44": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "4f30674320e349dda898a98bae208731": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "4f537e4a64cd468db1465d0a1cb305f3": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "51c3421d80ca44a48f7357c930fd6e8a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "5295198ea7c44d20b865edba3ae2282a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "52c022b8c8a64a84adea1f0b7ab7aba2": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "5638c8f569894e63a7aff7bbd82863bd": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "566744d9623e42fc974fb8634d9cc70c": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "5e8d4baeb550454a9129015501853118": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "621bfafd04c0462aa3ebdc0344df4cf7": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "633d14e5397d40dcb007e97513d676c5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "63a16de969094b41b88568342f775183": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "676f4badda9f42ec84ce8dd7827e621e": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "68b614fac25546429e0bc484a63ad4e1": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "69823d3307444ffa83eaebd1de35219e": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "6bd535e3837f4f00bfdf8882ce1a9a8d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "6c5cf8a06a544036a6d5155408df4716": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "74055007ea28464589051636190d9c8f": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7437478c243844f3b42fd64ca7ad8e1f": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "78d9fc73ca164d80af189db74a4c368b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "79a31698d54d47d79ba18d96def26233": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7a6827ed328c44d2b59bba058653873b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "7ccd1eb560e0440d9f97a3709b28bb56": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "842c25bca4de444ca97b2a2999cfac73": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "87b4cd422440498b981814d8e3cde6be": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "8c19dbdabf4e45efbac3701c15dc73ce": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "8c6652349887420ca2b3665b90dea2e1": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "92ae0de782ad4bfd9442f5856a5d8cb9": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "94087aaa2dd5453d8361de91cf15a951": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "967e2fb609ae4f6b8396c7ca91c216d6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "98240df983dd40df86e7f4c4c2a11089": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9a72894e55724eb48f5d14a16e63b6fc": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9b5092bcc131457989d641db2b3a33b1": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9e06722936144e53a0fe3c56aa0c3ccd": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9eb71c1f77794426a05e3c03a32894cd": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9eebf2f0f0c541b6be3acb4dbd015632": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "9f737f3035444b26aa05c2ff5e9d9ecb": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "a1e761846fe948d9b21d2970e69995fd": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "a4851df8a5194105a1912173da313feb": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "a78b6844b9cb4dbc8e0d47be5c546573": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "ab32a9866ba54eadb8470ccd8d7134ae": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "abd9a147f6564f08a109e06c736619af": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "ac2945c06a844cbc963fa4d9563a0d6d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "ac6e03b38c514210af0d71b9479a03fa": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "aebe47868ab64bd08ab31008425a71e2": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "aed4018423344fe5bceaf033817e9870": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "afa32857df2f4f239ee26736ce944e71": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b185136d606543b68702571d79f0ddd6": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b30a5db8cdf54fe69d46ede4ec581719": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b3285a7a18b4476182f956d2d7ce1333": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b5c6ffb0c83942518a53629df98ad83d": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "b829adec95034a54abf8042ef8f68ffb": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c0925622307746c19cc29b1ee2ee96a9": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c2432e5052624c32b3b3e6452b2e7e17": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c2c7177e4e0445bd972e721dc03e8e3b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c591bcc47c444b75807559150a3df398": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c865b6e3dd03449488253f32a9665f06": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "c9cdd7d821c0484092ff36f5253cfcf9": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "cb78a430848e4fa59d2a100ec63e6a30": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "cca5f4ed1b2b49d686f9ad23b619abd3": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "ce1af65dcfac493295d02a31f6652821": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "cfc83ee4ca5b435b960a818e992e6946": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "d14619df26034531987c36f6d7ff436b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "d25e8dc498e94162b18b5aa5ad621a11": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "d7246a0bcbd7473489ba979522a53b7c": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "d766a25d946b417d9650592712e30c99": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "e2b5fd3ef7a44d50b7736bfdd0936e1a": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "e99ef7571c9741e48e76d03e6725a4b5": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "ee13bb93608743c29ac668601d557292": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f30ac0ea6b8e41f697ba771c83eb9c0b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f3ec8e47564e4d27927d54dd31383a7f": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f41dfe3ca7874d5d85917acd533c30f8": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "f72e662fd8a9448282f9de4e74cc04e3": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "fa17cbd4a62c41479171b496123b86fa": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    },
    "fbac98fb007e41c9804c52e4482d0b8b": {
     "views": [
      {
       "cell_index": 29
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
